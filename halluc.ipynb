{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import imageio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from vae import HallucVAE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchvision.transforms import ToTensor\n",
    "from data import set_up_data, set_up_imagenet64\n",
    "from utils import get_cpu_stats_over_ranks\n",
    "from train_helpers import set_up_hyperparams, load_vaes, load_opt, accumulate_stats, save_model, update_ema, Hyperparams, add_vae_arguments, parse_args_and_update_hparams, setup_mpi, setup_save_dirs, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0264bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for loading the hyperparameters used to train the original VDVAE model\n",
    "def set_up_notebook_hps(s = None):\n",
    "    H = Hyperparams()\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = add_vae_arguments(parser)\n",
    "    parse_args_and_update_hparams(H, parser, s=s)\n",
    "    setup_mpi(H)\n",
    "    setup_save_dirs(H)\n",
    "    logprint = logger(H.logdir)\n",
    "    for i, k in enumerate(sorted(H)):\n",
    "        logprint(type='hparam', key=k, value=H[k])\n",
    "    np.random.seed(H.seed)\n",
    "    torch.manual_seed(H.seed)\n",
    "    # torch.cuda.manual_seed(H.seed)\n",
    "    logprint('training model', H.desc, 'on', H.dataset)\n",
    "    return H, logprint\n",
    "\n",
    "dataset = \"imagenet64\" # dataset used to train the VDVAE. Options are \"imagenet64\" and \"ffhq256\"\n",
    "\n",
    "if dataset == \"ffhq256\":\n",
    "    original_argv = sys.argv\n",
    "    sys.argv = ['halluc.ipynb', '--hps', 'ffhq256', '--restore_path', 'ffhq256-iter-1700000-model.th', '--restore_ema_path', 'ffhq256-iter-1700000-model-ema.th', '--restore_log_path', 'ffhq256-iter-1700000-log.jsonl', '--restore_optimizer_path', 'ffhq256-iter-1700000-opt.th', '--test_eval']\n",
    "\n",
    "    H, logprint = set_up_notebook_hps()\n",
    "    H, data_train, data_valid_or_test, preprocess_fn = set_up_data(H)\n",
    "    del data_train\n",
    "\n",
    "elif dataset == \"imagenet64\":\n",
    "    original_argv = sys.argv\n",
    "    sys.argv = ['halluc.ipynb', '--hps', 'imagenet64', '--restore_path', 'imagenet64-iter-1600000-model.th', '--restore_ema_path', 'imagenet64-iter-1600000-model-ema.th', '--restore_log_path', 'imagenet64-iter-1600000-log.jsonl', '--restore_optimizer_path', 'imagenet64-iter-1600000-opt.th', '--test_eval']\n",
    "\n",
    "    ds = load_dataset(\"zh-plus/tiny-imagenet\")\n",
    "    offset = 3\n",
    "    a = ds['valid']['image'][offset:(1000 + offset):100]\n",
    "    fig, ax = plt.subplots(1,10, figsize = (10*3, 3))\n",
    "    for ii in range(0,10):\n",
    "        ax[ii].imshow(a[ii])\n",
    "        ax[ii].set_xticks([])\n",
    "        ax[ii].set_yticks([])\n",
    "    to_tensor_transform = ToTensor()\n",
    "    valid_list = []\n",
    "    for im in ds['valid']['image']:\n",
    "        im_tensor = to_tensor_transform(im)\n",
    "        if im_tensor.shape[0] == 3:\n",
    "            valid_list.append(im_tensor)\n",
    "    validation_set = torch.stack(valid_list).permute([0,2,3,1])\n",
    "\n",
    "    H, logprint = set_up_notebook_hps()\n",
    "    H, data_valid_or_test, preprocess_fn = set_up_imagenet64(H, validation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a few sample input datapoints (and blank images) to avoid loading full datasets\n",
    "valid_sampler = RandomSampler(data_valid_or_test)\n",
    "data_loader =  DataLoader(data_valid_or_test, batch_size=1, drop_last=True, pin_memory=True, sampler=valid_sampler)\n",
    "batch_size = 10\n",
    "data_inputs = []\n",
    "data_zeros = []\n",
    "targets = []\n",
    "data_loader_iter = iter(data_loader)\n",
    "for ii in range(0, batch_size):\n",
    "    data = next(data_loader_iter)\n",
    "    data_input, target = preprocess_fn(data)\n",
    "    data_zero, _ = preprocess_fn([torch.zeros(data[0].shape)])\n",
    "    data_inputs.append(data_input)\n",
    "    data_zeros.append(data_zero)\n",
    "    targets.append(target)\n",
    "\n",
    "print(data_input.shape)\n",
    "torch.save([data_inputs, data_zeros, targets, H] , \"example_input.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f55a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H, logprint = set_up_notebook_hps()\n",
    "#load data and pretrained VDVAE model\n",
    "example_inputs, zero_inputs, targets, H= torch.load(\"example_input.pt\", weights_only=False)\n",
    "vae, ema_vae = load_vaes(H, logprint)\n",
    "input_data = torch.vstack(example_inputs)\n",
    "zero_data = torch.vstack(zero_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "halluc_vae = HallucVAE(ema_vae)\n",
    "\n",
    "#input-conditioned hallucinations\n",
    "step_num = 6\n",
    "abstraction_depth = 35 #use encoder for top K layers\n",
    "alpha_range = np.array([0., 0.6, 0.7, 0.8, 0.9, 1.0])#np.arange(0, 1.2, 0.2)\n",
    "samples = []\n",
    "for idx, a in enumerate(alpha_range):\n",
    "    sample, metrics = halluc_vae.mixed_sample(input_data, alpha = a, depth = abstraction_depth)\n",
    "    samples.append(sample)\n",
    "\n",
    "#closed eyes hallucinations\n",
    "zero_samples = []\n",
    "for idx, a in enumerate(alpha_range):\n",
    "    sample, metrics = halluc_vae.mixed_sample(zero_data, alpha = a, depth = abstraction_depth)\n",
    "    zero_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96469ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate open- and closed-eyes hallucination visualizations\n",
    "savepath = \"./\"\n",
    "sample_num = 3\n",
    "fig, ax = plt.subplots(sample_num, step_num, figsize = (3 * step_num, 3 * sample_num))\n",
    "if dataset == 'imagenet64':\n",
    "    sample_idxs = [2, 8, 9]\n",
    "elif dataset == 'ffhq256':\n",
    "    sample_idxs = [2, 5, 7]\n",
    "for ii in range(0, len(alpha_range)):\n",
    "    for jj in range(0, sample_num):\n",
    "        ax[jj,ii].imshow(samples[ii][sample_idxs[jj],...])\n",
    "        ax[jj,ii].set_xticks([])\n",
    "        ax[jj,ii].set_yticks([])\n",
    "    ax[0,ii].set_title(rf\"$\\alpha$ = {round(alpha_range[ii],2)}\", fontsize = 12)\n",
    "fig.savefig(savepath + f\"{dataset}_halluc.pdf\", format = 'pdf')\n",
    "sample_num = 3\n",
    "fig, ax = plt.subplots(sample_num, step_num, figsize = (3 * step_num, 3 * sample_num))\n",
    "for ii in range(0, len(alpha_range)):\n",
    "    for jj in range(0, sample_num):\n",
    "        ax[jj,ii].imshow(zero_samples[ii][sample_idxs[jj],...])\n",
    "        ax[jj,ii].set_xticks([])\n",
    "        ax[jj,ii].set_yticks([])\n",
    "    ax[0,ii].set_title(rf\"$\\alpha$ = {round(alpha_range[ii],2)}\", fontsize = 12)\n",
    "fig.savefig(savepath + f\"{dataset}_halluc_closed_eyes.pdf\", format = 'pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimulus conditioned representation variance\n",
    "# NOTE: runtime is ~30 minutes for this code cell\n",
    "from tqdm import tqdm\n",
    "valid_sampler = RandomSampler(data_valid_or_test)\n",
    "batch_size = 1\n",
    "data_loader =  DataLoader(data_valid_or_test, batch_size=1, drop_last=True, pin_memory=True, sampler=valid_sampler)\n",
    "\n",
    "halluc_vae = HallucVAE(ema_vae)\n",
    "\n",
    "sample_num = 100\n",
    "repetition_num = 32\n",
    "abstraction_depth = 35 #use encoder for top K layers\n",
    "alpha_range = np.arange(0, 1.1, 0.1)\n",
    "metrics = {a: [] for a in alpha_range}\n",
    "\n",
    "data_iterable = iter(data_loader)\n",
    "for ii in tqdm(range(0, sample_num)):\n",
    "    for idx, a in enumerate(alpha_range):\n",
    "        input_data = next(data_iterable)\n",
    "        data, _ = preprocess_fn(input_data)\n",
    "        data = data.repeat(repetition_num, 1, 1, 1)\n",
    "        sample, metric = halluc_vae.mixed_sample(data, alpha = a, depth = abstraction_depth, metrics = ['variance'])\n",
    "        metrics[a].append(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plots for stimulus-conditioned variance\n",
    "savepath = \"./\"\n",
    "res = 16 #corresponds to layer 30\n",
    "corresponding_layer = 30\n",
    "layer_vars = {a: [metrics[a][ii]['variance'][res] for ii in range(0, len(metrics[a]))] for a in metrics.keys()}\n",
    "layer_vars_mean = {a: torch.mean(torch.stack(layer_vars[a])) for a in layer_vars.keys()}\n",
    "layer_vars_sem = {a: torch.std(torch.stack(layer_vars[a]))/np.sqrt(len(torch.stack(layer_vars[a]))) for a in layer_vars.keys()}\n",
    "layer_vars_mean = torch.tensor(list(layer_vars_mean.values()))\n",
    "layer_vars_sem = torch.tensor(list(layer_vars_sem.values()))\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (3,3))\n",
    "plt.errorbar(alpha_range, layer_vars_mean, yerr = layer_vars_sem)\n",
    "plt.title(f'{dataset} layer {corresponding_layer}')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('stimulus conditioned variance')\n",
    "fig.savefig(savepath + f\"{dataset}_stim_cond_var.pdf\", format = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effects of top-down inactivation\n",
    "from tqdm import tqdm\n",
    "valid_sampler = RandomSampler(data_valid_or_test)\n",
    "batch_size = 100\n",
    "data_loader =  DataLoader(data_valid_or_test, batch_size=batch_size, drop_last=True, pin_memory=True, sampler=valid_sampler)\n",
    "\n",
    "halluc_vae = HallucVAE(ema_vae)\n",
    "\n",
    "abstraction_depth = 35 #use encoder for top K layers\n",
    "alpha_range = np.arange(0, 1.1, 0.1)\n",
    "metrics = {a: [] for a in alpha_range}\n",
    "metrics_inact = {a: [] for a in alpha_range}\n",
    "samples = {a: [] for a in alpha_range}\n",
    "\n",
    "sample_num = 1\n",
    "data_iterable = iter(data_loader)\n",
    "layer_inactivation_list = list(range(0,20)) #inactivate top 20 layers\n",
    "for ii in tqdm(range(0, sample_num)):\n",
    "    input_data = next(data_iterable)\n",
    "    for idx, a in enumerate(alpha_range):\n",
    "        data, _ = preprocess_fn(input_data)\n",
    "        sample, metric = halluc_vae.mixed_sample(data, alpha = a, depth = abstraction_depth, metrics = ['variance', 'spatial_covariance'])\n",
    "        metrics[a].append(metric)\n",
    "        samples[a].append(sample)\n",
    "\n",
    "        sample_inact, metric_inact = halluc_vae.mixed_sample(data, alpha = a, depth = abstraction_depth, metrics = ['variance'], inact_inputs = layer_inactivation_list)\n",
    "        metrics_inact[a].append(metric_inact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37896051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plots analyzing the effects of top-down inactivation\n",
    "savepath = \"./\"\n",
    "res = 16\n",
    "corresponding_layer = 30\n",
    "layer_vars = {a: [metrics[a][ii]['variance'][res] for ii in range(0, len(metrics[a]))] for a in metrics.keys()}\n",
    "layer_vars_inact = {a: [metrics_inact[a][ii]['variance'][res] for ii in range(0, len(metrics_inact[a]))] for a in metrics_inact.keys()}\n",
    "\n",
    "eps = 1e-3\n",
    "var_ratio_mean = {a: torch.mean((torch.stack(layer_vars_inact[a]) + eps) / (torch.stack(layer_vars[a]) + eps)) for a in layer_vars.keys()}\n",
    "var_ratio_std = {a: torch.std((torch.stack(layer_vars_inact[a]) + eps)/ (torch.stack(layer_vars[a]) + eps)) for a in layer_vars.keys()}\n",
    "var_ratio_mean = torch.tensor(list(var_ratio_mean.values()))\n",
    "var_ratio_std = torch.tensor(list(var_ratio_std.values()))\n",
    "var_ratio_sem = var_ratio_std / np.sqrt(np.prod(torch.stack(layer_vars_inact[0.]).shape))\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (3,3))\n",
    "plt.errorbar(alpha_range, var_ratio_mean, yerr = var_ratio_sem)\n",
    "plt.plot(alpha_range, torch.ones_like(var_ratio_mean), 'k')\n",
    "plt.title(f'{dataset} layer {corresponding_layer}')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('across-stimulus variance ratio')\n",
    "fig.savefig(savepath + f\"{dataset}_var_ratio_inact.pdf\", format = 'pdf')\n",
    "\n",
    "\n",
    "var_ratio_pop = {a: (torch.mean(torch.stack(layer_vars_inact[a])) + eps) / (torch.mean(torch.stack(layer_vars[a])) + eps) for a in layer_vars.keys()}\n",
    "var_ratio_pop = torch.tensor(list(var_ratio_pop.values()))\n",
    "fig, ax = plt.subplots(1,1,figsize = (3,3))\n",
    "plt.plot(alpha_range, var_ratio_pop)\n",
    "plt.plot(alpha_range, torch.ones_like(var_ratio_pop), 'k')\n",
    "# plt.plot(alpha_range, layer_vars_mean_inact)\n",
    "plt.title(f'{dataset} layer {corresponding_layer} pop var ratio')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('across-stimulus variance ratio')\n",
    "fig.savefig(savepath + f\"{dataset}_var_ratio_inact_population.pdf\", format = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation similarity plots\n",
    "def corr_similarity(mat_1, mat_2):\n",
    "    return torch.corrcoef(torch.stack([mat_1.flatten(), mat_2.flatten()]))[0,1]\n",
    "\n",
    "def cosine_similarity(mat_1, mat_2):\n",
    "    flat_1 =  mat_1.flatten() / torch.linalg.norm(mat_1.flatten(), keepdims = True)\n",
    "    flat_2 = mat_2.flatten() / torch.linalg.norm(mat_2.flatten(), keepdims = True)\n",
    "    return torch.matmul(flat_1, flat_2)\n",
    "\n",
    "savepath = \"./\"\n",
    "res = 16\n",
    "corresponding_layer = 30\n",
    "layer_covs = {a: [metrics[a][ii]['spatial_covariance'][res] for ii in range(0, len(metrics[a]))] for a in metrics.keys()}\n",
    "layer_stds = {a: torch.sqrt(torch.diag(torch.diag(layer_covs[a][0]))) for a in layer_covs.keys()}\n",
    "layer_corrs = {a: torch.linalg.inv(layer_stds[a]) @ layer_covs[a][0] @ torch.linalg.inv(layer_stds[a]) for a in layer_covs.keys()}\n",
    "\n",
    "correlation_similarities = {a: cosine_similarity(torch.triu(layer_corrs[0.].cpu(), diagonal = 1), torch.triu(layer_corrs[a].cpu(), diagonal = 1)) for a in layer_corrs.keys()}\n",
    "\n",
    "corr_sims = torch.tensor(list(correlation_similarities.values()))\n",
    "fig, ax = plt.subplots(1,1,figsize = (3,3))\n",
    "plt.scatter(alpha_range, corr_sims)\n",
    "plt.title(f'{dataset} layer {corresponding_layer} corr_sims')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('across-stimulus correlation similarity')\n",
    "plt.ylim([0,1])\n",
    "fig.savefig(savepath + f\"{dataset}_correlation_similarities.pdf\", format = 'pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiscale analysis (Laplacian pyramid)\n",
    "import pyrtools as pt\n",
    "\n",
    "alpha_range = np.arange(0, 1.1, 0.1)\n",
    "sample_idx = 3\n",
    "base_ims = samples[alpha_range[0]][0][sample_idx,...]\n",
    "base_coeffs = pt.pyramids.LaplacianPyramid(base_ims[...].mean(axis = 2))\n",
    "halluc_coeffs = []\n",
    "for ii in range(0, len(samples)):\n",
    "    halluc_coeffs.append(pt.pyramids.LaplacianPyramid(samples[alpha_range[ii]][0][sample_idx,...].mean(axis = 2)))\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(samples[alpha_range[0]][0][sample_idx,...])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "alpha_plot_vals = np.array([0., 0.4, 0.8])\n",
    "alpha_num = len(alpha_plot_vals)\n",
    "scale_num = len(base_coeffs.pyr_coeffs.keys())\n",
    "sample_num = 100\n",
    "\n",
    "fig, ax = plt.subplots(alpha_num, scale_num + 1, figsize = (1 * (scale_num + 1), 1 * alpha_num))\n",
    "for ii in range(0, alpha_num):\n",
    "    ax[ii,0].imshow(samples[alpha_plot_vals[ii]][0][sample_idx,...].mean(axis = 2), cmap = 'gray')\n",
    "    ax[ii,0].set_xticks([])\n",
    "    ax[ii,0].set_yticks([])\n",
    "    ax[ii,0].set_ylabel(rf'$\\alpha$ = {round(alpha_plot_vals[ii],2)}')\n",
    "    for jj in range(1, scale_num + 1):\n",
    "        if ii == 0:\n",
    "            ax[ii,jj].set_title(f'lvl = {jj}')\n",
    "        ax[ii,jj].imshow(halluc_coeffs[ii].pyr_coeffs[(jj - 1, 0)], cmap = 'gray')\n",
    "        ax[ii,jj].set_xticks([])\n",
    "        ax[ii,jj].set_yticks([])\n",
    "fig.savefig(savepath + f\"{dataset}_laplace_pyr_ims.pdf\", format = 'pdf')\n",
    "\n",
    "alpha_num = len(alpha_range)\n",
    "dists = torch.zeros(sample_num, alpha_num, scale_num)\n",
    "for zz in range(0, sample_num):\n",
    "    base_ims = samples[alpha_range[0]][0][zz,...]\n",
    "    base_coeffs = pt.pyramids.LaplacianPyramid(base_ims[...].mean(axis = 2))\n",
    "    halluc_coeffs = []\n",
    "    for ii in range(0, len(samples)):\n",
    "        halluc_coeffs.append(pt.pyramids.LaplacianPyramid(samples[alpha_range[ii]][0][zz,...].mean(axis = 2)))\n",
    "    \n",
    "    for ii in range(0, alpha_num):\n",
    "        for jj in range(0, scale_num):\n",
    "            lp_coeff_base = base_coeffs.pyr_coeffs[(jj, 0)]\n",
    "            lp_coeff_alpha = halluc_coeffs[ii].pyr_coeffs[(jj, 0)]\n",
    "            dists[zz,ii,jj] = corr_similarity(torch.tensor(lp_coeff_base), torch.tensor(lp_coeff_alpha))#psnr(lp_coeff_base, lp_coeff_alpha) #np.mean((lp_coeff_base - lp_coeff_alpha)**2)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (3,3))\n",
    "\n",
    "scale_list = [0,1,2,3,4]\n",
    "cmap = plt.cm.Greys(np.linspace(0.2,1,  len(scale_list)))\n",
    "dists = dists #/ torch.max(dists, 0, keepdim = True)[0]\n",
    "for ii in range(0, len(scale_list)):\n",
    "    dist_mean = torch.mean(dists[:,:,ii], axis = 0)\n",
    "    dist_sem = torch.std(dists[:,:,ii], axis = 0) / torch.sqrt(torch.tensor([sample_num]))\n",
    "    plt.errorbar(alpha_range, dist_mean, yerr = dist_sem, color = cmap[ii])\n",
    "plt.legend(scale_list)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('base image correlation similarity')\n",
    "fig.savefig(savepath + f\"{dataset}_laplace_pyr_summary.pdf\", format = 'pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vdvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
